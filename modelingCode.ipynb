{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# data는 데이터프레임 이름으로 수정하면됨\n",
    "X = pd.DataFrame(data, columns= ['구매시월령(수정)'])\n",
    "Y = pd.DataFrame(data, columns= ['기저귀 단계'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "gbrt = GradientBoostingClassifier(max_depth = 3, learning_rate = 0.01)\n",
    "gbrt.fit(X_train_std, Y_train)\n",
    "gbrt_train_score = gbrt.score(X_train_std, Y_train)\n",
    "gbrt_test_score = gbrt.score(X_test_std, Y_test)\n",
    "print(f'그레디언트부스팅 훈련 정확도는 {round(gbrt_train_score,3)} 입니다.')\n",
    "print(f'그레디언트부스팅 테스트 정확도는 {round(gbrt_test_score,3)} 입니다.')\n",
    "# Gradient boosting 모델 생성, 정확도 확인. max_depth = 3, learning_rate = 0.01일때 최고의 정확도가 나옴.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_gbrt = gbrt.predict(X_test_std)\n",
    "\n",
    "gbrt_conf = confusion_matrix(Y_test, pred_gbrt)\n",
    "print(gbrt_conf)\n",
    "\n",
    "gbrt_report = classification_report(Y_test, pred_gbrt)\n",
    "print(gbrt_report)\n",
    "# Gradient boosting 상세\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 5)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "train_accuracy = model.score(X_train, Y_train)\n",
    "test_accuracy = model.score(X_test, Y_test)\n",
    "print(f'훈련 정확도는 {round(train_accuracy,3)} 입니다.')\n",
    "print(f'테스트 정확도는 {round(test_accuracy,3)} 입니다.')\n",
    "# Decision Tree 모델 생성, 정확도 확인. max_depth = 3일때 최고의 정확도가 나옴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤포레스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.DataFrame(data, columns = ['구매시월령(수정)','구매일','결혼유무','자녀여부'])\n",
    "Y = pd.DataFrame(data, columns = ['기저귀 단계'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth = 6,\n",
    "                                n_estimators=150)\n",
    "clf_rf.fit(X_train_std, Y_train['기저귀 단계'].ravel())\n",
    "\n",
    "pred_rf = clf_rf.predict(X_test_std)\n",
    "\n",
    "rf_train_score = clf_rf.score(X_train_std, Y_train['기저귀 단계'].ravel())\n",
    "rf_test_score = clf_rf.score(X_test_std, Y_test['기저귀 단계'].ravel())\n",
    "print(f'랜덤포레스트 훈련 정확도는 {round(rf_train_score,3)} 입니다.')\n",
    "print(f'랜덤포레스트 테스트 정확도는 {round(rf_test_score,3)} 입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(Y_test['기저귀 단계'].ravel(), pred_rf)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(Y_test['기저귀 단계'].ravel(), pred_rf)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#터미널에 conda update --all\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split #데이터를 훈련집합이랑 시험집합으로 나눔\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV #교차검증\n",
    "from sklearn.metrics import confusion_matrix #혼동행렬\n",
    "from sklearn.metrics import plot_confusion_matrix #혼동행렬 그리기용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop('',axis = 1).copy()\n",
    "y= data[''].copy()\n",
    "\n",
    "X_encoding = pd.get_dummies(X, columns = [''])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_encoding,y,stratify=y)\n",
    "\n",
    "#일정한 결과를 얻고자 한다면 seed = 42 인자추가\n",
    "clf_xgb = xgb.XGBClassifier(objextive='',missing=None)\n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose = True,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='aucpr',\n",
    "            eval_set[(X_test, y_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_xgb,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    values_format='d',\n",
    "                    display_labels=['',''])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "\t'max_depth':[3,4,5],\n",
    "        'learning_rate':[1, 0.5, 0.1, 0.01, 0.05],\n",
    "        'gamma':[0, 0.25, 1.0],\n",
    "        'reg_lambda': [0, 1.0, 10.0, 20, 100],\n",
    "        'scale_pos_weight': [1, 3, 5]\n",
    "       }\n",
    "       \n",
    "optimal_params = GridSearchCV(\n",
    "      estimator=xgb.XGBClassifier(objective='binary:logistic',\n",
    "    \t\t\t\t    subsample=0.9,\n",
    "                          \t    colsample_bytree=0.5),\n",
    "      param_grid=param_grid,\n",
    "      scoring='roc_auc',\n",
    "      verbose=0, #뭐하는지 알고 싶으면 2로 설정해볼 것\n",
    "      n_jobs=10,\n",
    "      cv=3\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "\t\t\t    gamma=0.25,\n",
    "                            learn_rate=0.1,\n",
    "                            max_depth=4,\n",
    "                            reg_lambda=10,\n",
    "                            scale_pos_weight=3,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5)\n",
    "clf_xgb.fit(X_train,\n",
    "\t    y_train,\n",
    "            verbose=True,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='aucpr',\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "\t\t\t    gamma=0.25,\n",
    "                            learn_rate=0.1,\n",
    "                            max_depth=4,\n",
    "                            reg_lambda=10,\n",
    "                            scale_pos_weight=3,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5,\n",
    "                            n_estimators=1)\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb.to_graphviz(clf_xgb, num_tress=0, size=\"10,10\",\n",
    "\t\tcondition_node_params=node_params,\n",
    "                leaf_node_params=lear_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014a1d4f4127abf91d419a90ea146722ef617667aa392137e996c5d4104c429e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
